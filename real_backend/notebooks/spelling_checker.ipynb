{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6847420b-8fca-4247-bdfe-7d5286f1c1cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\parkc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\parkc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\parkc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\parkc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\parkc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61dc3d6c-d042-460a-89b5-79afa3d9905e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "from nltk.util import trigrams\n",
    "from nltk.util import bigrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.collocations import *\n",
    "import re\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28dfb690-cd32-4628-a562-c5b87673c786",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_tags_list = list(map(list, zip(*nltk.pos_tag(brown.words(categories='news')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0e6df88-8a17-40dc-8e2b-43595aea73cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tri_pos_freqdist = nltk.FreqDist(trigrams(words_tags_list[1]))\n",
    "dict_tri_words_freqdist = nltk.FreqDist(trigrams(words_tags_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f383a91-0a81-47de-b75b-82f24be4f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "fourgram_measures = nltk.collocations.QuadgramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "4677f7c7-066d-44e6-bdfd-a8d759eb3e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creature_filter = lambda *w: 'he am take' not in w\n",
    "finder = BigramCollocationFinder.from_words(brown.words(categories='news'))\n",
    "#finder.apply_freq_filter(1)\n",
    "finder.apply_ngram_filter(creature_filter)\n",
    "finder.nbest(bigram_measures.pmi, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de51a515-b193-4b45-b897-e19ddcea75e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 'running')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = 'running'\n",
    "creature_filter = lambda *w: token not in w\n",
    "finder = BigramCollocationFinder.from_words(brown.words())\n",
    "finder.apply_freq_filter(10)\n",
    "finder.apply_ngram_filter(creature_filter)\n",
    "finder.nbest(trigram_measures.pmi, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732cc91d",
   "metadata": {},
   "source": [
    "## 1. Generate candidate set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea24026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics import jaccard_distance\n",
    "from nltk.metrics.distance  import edit_distance\n",
    "from nltk.corpus import words\n",
    "from nltk.util import ngrams\n",
    "from nltk.util import trigrams\n",
    "from nltk.util import bigrams\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7538f6f-13a7-4765-ba1a-4c6df8ae5b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pos_tags(tokens):\n",
    "    return list(map(list, zip(*nltk.pos_tag(tokens))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45bbcb50-29e8-4ae4-be2b-d789e2119897",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = {}\n",
    "letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "for word in words.words():\n",
    "    #word_ = word.lower()\n",
    "    if word[0].lower() not in ind:\n",
    "        ind[word[0].lower()] = set()\n",
    "    ind[word[0].lower()].add(word)\n",
    "for letter in letters:\n",
    "    if letter not in ind:\n",
    "        ind[letter] = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c157623a-06fe-4bb0-b270-f9695d02e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_pos = generate_pos_tags(brown.words())\n",
    "brown_bg = list(bigrams(brown_pos[0]))\n",
    "brown_tg = list(trigrams(brown_pos[0]))\n",
    "brown_bg_pos = list(bigrams(brown_pos[1]))\n",
    "brown_tg_pos = list(trigrams(brown_pos[1]))\n",
    "#Frequency distribution for Words\n",
    "freq_dist = nltk.FreqDist(brown.words())\n",
    "freq_dist_bigrams = nltk.FreqDist(list(bigrams(brown.words())))\n",
    "freq_dist_trigrams = nltk.FreqDist(list(trigrams(brown.words())))\n",
    "#Frequency distribution for POS tags\n",
    "freq_dist_pos = nltk.FreqDist(brown_pos[1])\n",
    "freq_dist_bg_pos = nltk.FreqDist(brown_bg_pos)\n",
    "freq_dist_tg_pos = nltk.FreqDist(brown_tg_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa58173c-50dd-415e-9228-a08b23f85fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_spellings = words.words()\n",
    "max_dist = 5\n",
    "min_word = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faccd9a5-6e5c-4c01-949f-83074965c2d5",
   "metadata": {},
   "source": [
    "## Non-word spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "bdb58cb1-b9a5-4cd2-af32-8f7e4c5d4cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He', 'is', 'runing', 'to', 'bus', 'stp']\n",
      "[('He', 'is'), ('is', 'runing'), ('runing', 'to'), ('to', 'bus'), ('bus', 'stp')]\n"
     ]
    }
   ],
   "source": [
    "entries = word_tokenize(re.sub(r'[^\\w]', ' ', 'He is runing to bus stp.'))\n",
    "print(entries)\n",
    "bigrams_ = list(bigrams(entries))\n",
    "print(bigrams_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "f11d0349-e836-415f-9a6d-b353cedc4d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 567 ms\n",
      "Edit distance\n",
      "Wall time: 1.03 ms\n",
      "{'racing': [('is', 'racing'), ('racing', 'to')], 'raging': [('is', 'raging'), ('raging', 'to')], 'raking': [('is', 'raking'), ('raking', 'to')], 'randing': [('is', 'randing'), ('randing', 'to')], 'ranging': [('is', 'ranging'), ('ranging', 'to')], 'ranine': [('is', 'ranine'), ('ranine', 'to')], 'ranting': [('is', 'ranting'), ('ranting', 'to')], 'raping': [('is', 'raping'), ('raping', 'to')], 'rating': [('is', 'rating'), ('rating', 'to')], 'raving': [('is', 'raving'), ('raving', 'to')], 'reking': [('is', 'reking'), ('reking', 'to')], 'renin': [('is', 'renin'), ('renin', 'to')], 'rering': [('is', 'rering'), ('rering', 'to')], 'resing': [('is', 'resing'), ('resing', 'to')], 'riding': [('is', 'riding'), ('riding', 'to')], 'ring': [('is', 'ring'), ('ring', 'to'), ('is', 'ring'), ('ring', 'to')], 'ringing': [('is', 'ringing'), ('ringing', 'to')], 'rinsing': [('is', 'rinsing'), ('rinsing', 'to')], 'rising': [('is', 'rising'), ('rising', 'to')], 'riving': [('is', 'riving'), ('riving', 'to')], 'robing': [('is', 'robing'), ('robing', 'to')], 'roding': [('is', 'roding'), ('roding', 'to')], 'roping': [('is', 'roping'), ('roping', 'to')], 'rounding': [('is', 'rounding'), ('rounding', 'to')], 'rousing': [('is', 'rousing'), ('rousing', 'to')], 'routing': [('is', 'routing'), ('routing', 'to')], 'roving': [('is', 'roving'), ('roving', 'to')], 'rowing': [('is', 'rowing'), ('rowing', 'to')], 'rubbing': [('is', 'rubbing'), ('rubbing', 'to')], 'rubine': [('is', 'rubine'), ('rubine', 'to')], 'ruching': [('is', 'ruching'), ('ruching', 'to')], 'rugging': [('is', 'rugging'), ('rugging', 'to')], 'ruin': [('is', 'ruin'), ('ruin', 'to')], 'ruing': [('is', 'ruing'), ('ruing', 'to')], 'ruling': [('is', 'ruling'), ('ruling', 'to')], 'rung': [('is', 'rung'), ('rung', 'to')], 'runic': [('is', 'runic'), ('runic', 'to')], 'runite': [('is', 'runite'), ('runite', 'to')], 'running': [('is', 'running'), ('running', 'to')], 'runny': [('is', 'runny'), ('runny', 'to')], 'runrig': [('is', 'runrig'), ('runrig', 'to')], 'rushing': [('is', 'rushing'), ('rushing', 'to')], 'rusine': [('is', 'rusine'), ('rusine', 'to')], 'rutin': [('is', 'rutin'), ('rutin', 'to')]}\n",
      "Frequency distribution by word\n",
      "[('running', 119), ('rising', 60), ('riding', 43), ('ring', 40), ('ranging', 30), ('racing', 21), ('ruling', 19), ('ruin', 14), ('rubbing', 11), ('rushing', 10), ('rating', 9), ('ringing', 9), ('rousing', 8), ('rounding', 5), ('rinsing', 4), ('raving', 3), ('rung', 3), ('raging', 2), ('roving', 2), ('raping', 1)]\n",
      "Frequency distribution by bigrams\n",
      "[('running', 11), ('rising', 3), ('racing', 1), ('raging', 1), ('rating', 1), ('riding', 1), ('rubbing', 1), ('ruin', 1), ('rushing', 1)]\n",
      "2\n",
      "Wall time: 794 ms\n",
      "Edit distance\n",
      "Wall time: 2 ms\n",
      "{'s': [('bus', 's')], 'sa': [('bus', 'sa')], 'saa': [('bus', 'saa')], 'sab': [('bus', 'sab')], 'sac': [('bus', 'sac')], 'sad': [('bus', 'sad'), ('bus', 'sad')], 'sag': [('bus', 'sag')], 'sah': [('bus', 'sah')], 'sai': [('bus', 'sai')], 'saip': [('bus', 'saip')], 'saj': [('bus', 'saj')], 'sal': [('bus', 'sal')], 'salp': [('bus', 'salp')], 'sam': [('bus', 'sam')], 'samp': [('bus', 'samp')], 'san': [('bus', 'san')], 'sao': [('bus', 'sao')], 'sap': [('bus', 'sap')], 'sapa': [('bus', 'sapa')], 'sapo': [('bus', 'sapo')], 'sar': [('bus', 'sar')], 'sat': [('bus', 'sat')], 'sate': [('bus', 'sate')], 'saw': [('bus', 'saw')], 'sax': [('bus', 'sax')], 'say': [('bus', 'say'), ('bus', 'say')], 'scap': [('bus', 'scap')], 'scup': [('bus', 'scup')], 'se': [('bus', 'se')], 'sea': [('bus', 'sea'), ('bus', 'sea')], 'sec': [('bus', 'sec')], 'see': [('bus', 'see'), ('bus', 'see')], 'seep': [('bus', 'seep')], 'seg': [('bus', 'seg')], 'sen': [('bus', 'sen')], 'seps': [('bus', 'seps')], 'sept': [('bus', 'sept')], 'ser': [('bus', 'ser')], 'set': [('bus', 'set')], 'seta': [('bus', 'seta')], 'seth': [('bus', 'seth')], 'sett': [('bus', 'sett')], 'setup': [('bus', 'setup')], 'sew': [('bus', 'sew')], 'sex': [('bus', 'sex'), ('bus', 'sex')], 'sey': [('bus', 'sey')], 'sh': [('bus', 'sh')], 'sha': [('bus', 'sha')], 'shap': [('bus', 'shap')], 'she': [('bus', 'she')], 'shi': [('bus', 'shi')], 'ship': [('bus', 'ship'), ('bus', 'ship')], 'sho': [('bus', 'sho')], 'shop': [('bus', 'shop')], 'shy': [('bus', 'shy')], 'si': [('bus', 'si')], 'sib': [('bus', 'sib')], 'sic': [('bus', 'sic')], 'sie': [('bus', 'sie')], 'sig': [('bus', 'sig')], 'sil': [('bus', 'sil')], 'simp': [('bus', 'simp')], 'sin': [('bus', 'sin')], 'sip': [('bus', 'sip')], 'sipe': [('bus', 'sipe')], 'sir': [('bus', 'sir')], 'sis': [('bus', 'sis')], 'sit': [('bus', 'sit')], 'site': [('bus', 'site')], 'sith': [('bus', 'sith')], 'six': [('bus', 'six')], 'skep': [('bus', 'skep')], 'ski': [('bus', 'ski')], 'skip': [('bus', 'skip')], 'sky': [('bus', 'sky'), ('bus', 'sky')], 'sla': [('bus', 'sla')], 'slap': [('bus', 'slap')], 'slip': [('bus', 'slip'), ('bus', 'slip')], 'slop': [('bus', 'slop')], 'sly': [('bus', 'sly')], 'sma': [('bus', 'sma')], 'snap': [('bus', 'snap')], 'snip': [('bus', 'snip')], 'snop': [('bus', 'snop')], 'snup': [('bus', 'snup')], 'sny': [('bus', 'sny')], 'so': [('bus', 'so'), ('bus', 'so')], 'soap': [('bus', 'soap'), ('bus', 'soap')], 'sob': [('bus', 'sob')], 'soc': [('bus', 'soc')], 'sod': [('bus', 'sod')], 'soe': [('bus', 'soe')], 'sog': [('bus', 'sog')], 'soh': [('bus', 'soh')], 'sok': [('bus', 'sok')], 'sol': [('bus', 'sol')], 'son': [('bus', 'son'), ('bus', 'son')], 'sop': [('bus', 'sop')], 'sope': [('bus', 'sope')], 'soph': [('bus', 'soph')], 'sot': [('bus', 'sot')], 'sots': [('bus', 'sots')], 'sou': [('bus', 'sou')], 'soup': [('bus', 'soup'), ('bus', 'soup')], 'sov': [('bus', 'sov')], 'sow': [('bus', 'sow')], 'soy': [('bus', 'soy')], 'spa': [('bus', 'spa')], 'spy': [('bus', 'spy')], 'sri': [('bus', 'sri')], 'ssu': [('bus', 'ssu')], 'st': [('bus', 'st')], 'stab': [('bus', 'stab')], 'stag': [('bus', 'stag')], 'stam': [('bus', 'stam')], 'stamp': [('bus', 'stamp'), ('bus', 'stamp')], 'stap': [('bus', 'stap')], 'star': [('bus', 'star'), ('bus', 'star')], 'staup': [('bus', 'staup')], 'staw': [('bus', 'staw')], 'stay': [('bus', 'stay')], 'steep': [('bus', 'steep')], 'steg': [('bus', 'steg')], 'stem': [('bus', 'stem'), ('bus', 'stem')], 'sten': [('bus', 'sten')], 'step': [('bus', 'step'), ('bus', 'step')], 'stept': [('bus', 'stept')], 'stet': [('bus', 'stet')], 'stew': [('bus', 'stew')], 'stey': [('bus', 'stey')], 'stib': [('bus', 'stib')], 'stid': [('bus', 'stid')], 'stim': [('bus', 'stim')], 'stipe': [('bus', 'stipe')], 'stir': [('bus', 'stir')], 'stirp': [('bus', 'stirp')], 'stoa': [('bus', 'stoa')], 'stob': [('bus', 'stob')], 'stod': [('bus', 'stod')], 'stoep': [('bus', 'stoep')], 'stof': [('bus', 'stof')], 'stog': [('bus', 'stog')], 'stomp': [('bus', 'stomp')], 'stoop': [('bus', 'stoop')], 'stop': [('bus', 'stop'), ('bus', 'stop')], 'stopa': [('bus', 'stopa')], 'stope': [('bus', 'stope')], 'stot': [('bus', 'stot')], 'stoup': [('bus', 'stoup')], 'stow': [('bus', 'stow')], 'stra': [('bus', 'stra')], 'strap': [('bus', 'strap')], 'stre': [('bus', 'stre')], 'strip': [('bus', 'strip')], 'strop': [('bus', 'strop')], 'stub': [('bus', 'stub')], 'stud': [('bus', 'stud')], 'stue': [('bus', 'stue')], 'stug': [('bus', 'stug')], 'stum': [('bus', 'stum')], 'stump': [('bus', 'stump')], 'stun': [('bus', 'stun')], 'stupa': [('bus', 'stupa')], 'stupe': [('bus', 'stupe')], 'stupp': [('bus', 'stupp')], 'stut': [('bus', 'stut')], 'sty': [('bus', 'sty')], 'sub': [('bus', 'sub')], 'sud': [('bus', 'sud')], 'sue': [('bus', 'sue')], 'sum': [('bus', 'sum')], 'sump': [('bus', 'sump')], 'sun': [('bus', 'sun'), ('bus', 'sun')], 'sup': [('bus', 'sup')], 'supa': [('bus', 'supa')], 'supe': [('bus', 'supe')], 'sur': [('bus', 'sur')], 'suz': [('bus', 'suz')], 'swa': [('bus', 'swa')], 'swap': [('bus', 'swap')], 'swep': [('bus', 'swep')], 'sye': [('bus', 'sye')]}\n",
      "Frequency distribution by word\n",
      "[('she', 1949), ('so', 1755), ('see', 728), ('say', 495), ('set', 408), ('saw', 350), ('six', 196), ('sat', 149), ('son', 140), ('step', 130), ('stop', 110), ('stay', 107), ('sun', 102), ('ship', 82), ('sex', 81), ('sea', 80), ('sit', 65), ('site', 64), ('shop', 56), ('sky', 56), ('sin', 53), ('sum', 44), ('sad', 34), ('sir', 34), ('stem', 30), ('strip', 29), ('soap', 21), ('slip', 19), ('star', 16), ('soup', 14), ('steep', 13), ('sue', 13), ('snap', 12), ('shy', 10), ('spy', 9), ('se', 8), ('setup', 8), ('stag', 8), ('stamp', 8), ('stir', 7), ('stud', 7), ('sax', 6), ('sew', 6), ('sly', 5), ('stew', 5), ('sub', 5), ('sag', 4), ('stoop', 4), ('ski', 3), ('skip', 3), ('sod', 3), ('sow', 3), ('stab', 3), ('stub', 3), ('seep', 2), ('sip', 2), ('slap', 2), ('slop', 2), ('strap', 2), ('stump', 2), ('swap', 2), ('sap', 1), ('sic', 1), ('soe', 1), ('sop', 1), ('sou', 1), ('soy', 1), ('spa', 1), ('sup', 1), ('sur', 1)]\n",
      "Frequency distribution by bigrams\n",
      "[('stop', 2)]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for position, entry in enumerate(entries):\n",
    "    entry = entry.lower()\n",
    "    if entry not in correct_spellings:\n",
    "        #%time temp_jaccard = [(jaccard_distance(set(ngrams(entry, 2)), set(ngrams(w, 2))),w) for w in correct_spellings if w[0]==entry[0]]\n",
    "        %time temp_edit = [(edit_distance(entry, w),w) for w in correct_spellings if w[0]==entry[0]]\n",
    "        print(\"Edit distance\")\n",
    "        i = 2\n",
    "        %time edit_set = [x for x in temp_edit if x[0] <= i]\n",
    "        while len(edit_set) < min_word & i < max_dist:\n",
    "            i = i + 1\n",
    "            edit_set = [x for x in temp_edit if x[0] <= i]\n",
    "        freqs_1 = {}\n",
    "        for word in edit_set:\n",
    "            if word[1] in freq_dist:\n",
    "                freqs_1[word[1]] = freq_dist[word[1]]\n",
    "        entry_bigrams = [x for x in bigrams_ if (entry in x)]\n",
    "        candidate_bigrams = {}\n",
    "        #create bigrams candidate set\n",
    "        for correction in edit_set:\n",
    "            for pos_, x in enumerate(entry_bigrams):\n",
    "                for j in range(len(x)):\n",
    "                    if x[j] == entry:\n",
    "                        y = list(x)\n",
    "                        y[j] = correction[1]\n",
    "                        x = tuple(y)\n",
    "                if correction[1] not in candidate_bigrams:\n",
    "                    candidate_bigrams[correction[1]] = list()\n",
    "                candidate_bigrams[correction[1]].append(x)\n",
    "        print(candidate_bigrams)\n",
    "        freqs_2 = {}\n",
    "        for candidate, cbigrams in candidate_bigrams.items():\n",
    "            for cbigram in cbigrams: \n",
    "                if cbigram in freq_dist_bigrams:\n",
    "                    if candidate not in freqs_2:\n",
    "                        freqs_2[candidate] = 0\n",
    "                    freqs_2[candidate] = freqs_2[candidate] + freq_dist_bigrams[cbigram]\n",
    "        print('Frequency distribution by word')\n",
    "        print(sorted(freqs_1.items(), key=itemgetter(1), reverse=True))\n",
    "        print('Frequency distribution by bigrams')\n",
    "        print(sorted(freqs_2.items(), key=itemgetter(1), reverse=True))\n",
    "        print(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7f8c8e8-a422-4523-a2e0-6a8f91372217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates(entry, distance=2, min_word=10, max_dist=5):\n",
    "    entry = entry.lower()\n",
    "    temp_edit = [(edit_distance(entry, w),w) for w in ind[entry[0]]]\n",
    "    i = distance\n",
    "    edit_set = [x for x in temp_edit if x[0] <= i]\n",
    "    while len(edit_set) < min_word & i < max_dist:\n",
    "        i = i + 1\n",
    "        edit_set = [x for x in temp_edit if x[0] <= i]\n",
    "    edit_set = set([x[1] for x in edit_set])\n",
    "    return edit_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "15839897-275e-4280-b023-7720da3bb110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('is', 'taking') in brown_bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "fac9fa21-b42e-488f-bd13-e579ad9a12e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({(\"''\", '?', '?'): 915, (\"''\", '.', '``'): 702, (',', 'and', 'the'): 652, ('.', 'It', 'is'): 529, ('.', 'It', 'was'): 518, ('.', 'In', 'the'): 398, ('?', '?', '``'): 381, ('.', '``', 'I'): 359, (\"''\", '!', '!'): 350, (\"''\", ',', 'he'): 346, ...})"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('is', 'taking', 'to') in freq_dist_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc81fd5e-7556-400c-acde-3482e92d307e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('he', 'is'), ('is', 'taken'), ('taken', 'the'), ('the', 'basket'), ('basket', 'to'), ('to', 'the'), ('the', 'laundry')]\n",
      "('he', 'is')\n",
      "True\n",
      "[]\n",
      "('is', 'taken')\n",
      "True\n",
      "[]\n",
      "('taken', 'the')\n",
      "True\n",
      "[]\n",
      "('the', 'basket')\n",
      "True\n",
      "[]\n",
      "('basket', 'to')\n",
      "False\n",
      "basket\n",
      "to\n",
      "[(('bugle', 'to'), 1.0), (('bower', 'to'), 1.0), (('beau', 'to'), 1.0), (('backside', 'to'), 1.0), (('belong', 'to'), 0.6216216216216216), (('bonnet', 'to'), 0.5), (('butler', 'to'), 0.5), (('bonded', 'to'), 0.5), (('besieged', 'to'), 0.5), (('batter', 'to'), 0.5), (('begun', 'to'), 0.49019607843137253), (('bound', 'to'), 0.35714285714285715), (('boon', 'to'), 0.3333333333333333), (('bug', 'to'), 0.3333333333333333), (('bayonet', 'to'), 0.3333333333333333), (('begin', 'to'), 0.32926829268292684), (('blow', 'to'), 0.2727272727272727), (('bravery', 'to'), 0.25), (('blues', 'to'), 0.25), (('braces', 'to'), 0.25), (('beaten', 'to'), 0.23076923076923078), (('bother', 'to'), 0.22727272727272727), (('barrier', 'to'), 0.2222222222222222), (('blown', 'to'), 0.2222222222222222), (('back', 'to'), 0.21263157894736842), (('braced', 'to'), 0.2), (('beacon', 'to'), 0.2), (('Beth', 'to'), 0.2), (('bodily', 'to'), 0.16666666666666666), (('bulletin', 'to'), 0.16666666666666666), (('bail', 'to'), 0.14285714285714285), (('buckskin', 'to'), 0.14285714285714285), (('bowed', 'to'), 0.14285714285714285), (('brutal', 'to'), 0.14285714285714285), (('barefoot', 'to'), 0.14285714285714285), (('barred', 'to'), 0.125), (('baroque', 'to'), 0.125), (('battered', 'to'), 0.1111111111111111), (('balloon', 'to'), 0.1111111111111111), (('biwa', 'to'), 0.1111111111111111), (('bulky', 'to'), 0.1111111111111111), (('boiled', 'to'), 0.1), (('burned', 'to'), 0.1), (('backward', 'to'), 0.09523809523809523), (('brought', 'to'), 0.09486166007905138), (('beg', 'to'), 0.09090909090909091), (('block', 'to'), 0.09090909090909091), (('bent', 'to'), 0.08823529411764706), (('ballot', 'to'), 0.08333333333333333), (('bubble', 'to'), 0.08333333333333333), (('belt', 'to'), 0.07692307692307693), (('barbecue', 'to'), 0.07692307692307693), (('Bari', 'to'), 0.07142857142857142), (('bark', 'to'), 0.07142857142857142), (('branch', 'to'), 0.07142857142857142), (('bow', 'to'), 0.07142857142857142), (('battery', 'to'), 0.06666666666666667), (('boost', 'to'), 0.06666666666666667), (('blind', 'to'), 0.06521739130434782), (('birth', 'to'), 0.06349206349206349), (('beer', 'to'), 0.0625), (('best', 'to'), 0.06158357771260997), (('bone', 'to'), 0.06060606060606061), (('bridge', 'to'), 0.060240963855421686), (('brains', 'to'), 0.058823529411764705), (('basket', 'there'), 0.058823529411764705), (('bear', 'to'), 0.05660377358490566), (('baby', 'to'), 0.05263157894736842), (('bend', 'to'), 0.05263157894736842), (('bet', 'to'), 0.05263157894736842), (('battle', 'to'), 0.05128205128205128), (('bring', 'to'), 0.05128205128205128), (('brave', 'to'), 0.05), (('benefit', 'to'), 0.04838709677419355), (('bid', 'to'), 0.047619047619047616), (('better', 'to'), 0.04477611940298507), (('balance', 'to'), 0.044444444444444446), (('builder', 'to'), 0.038461538461538464), (('bought', 'to'), 0.03571428571428571), (('blood', 'to'), 0.03508771929824561), (('budget', 'to'), 0.03508771929824561), (('Bible', 'to'), 0.03389830508474576), (('basement', 'to'), 0.03333333333333333), (('blanket', 'to'), 0.03333333333333333), (('beach', 'to'), 0.030303030303030304), (('bomb', 'to'), 0.030303030303030304), (('business', 'to'), 0.030303030303030304), (('book', 'to'), 0.028409090909090908), (('born', 'to'), 0.02727272727272727), (('bottle', 'to'), 0.02631578947368421), (('bill', 'to'), 0.02564102564102564), (('bread', 'to'), 0.024390243902439025), (('bag', 'to'), 0.023809523809523808), (('board', 'to'), 0.023529411764705882), (('bond', 'to'), 0.023255813953488372), (('band', 'to'), 0.022727272727272728), (('burden', 'to'), 0.022727272727272728), (('bank', 'to'), 0.018518518518518517), (('busy', 'to'), 0.017241379310344827), (('Boston', 'to'), 0.01639344262295082), (('basis', 'to'), 0.016304347826086956), (('beat', 'to'), 0.015384615384615385), (('beauty', 'to'), 0.014925373134328358), (('boat', 'to'), 0.014492753623188406), (('brother', 'to'), 0.014084507042253521), (('broke', 'to'), 0.014084507042253521), (('bar', 'to'), 0.014084507042253521), (('bottom', 'to'), 0.0125), (('basic', 'to'), 0.012269938650306749), (('broad', 'to'), 0.012195121951219513), (('base', 'to'), 0.011904761904761904), (('but', 'to'), 0.011306950448952444), (('body', 'to'), 0.011152416356877323), (('both', 'to'), 0.01088646967340591), (('blue', 'to'), 0.010309278350515464), (('built', 'to'), 0.009900990099009901), (('bit', 'to'), 0.009900990099009901), (('ball', 'to'), 0.009900990099009901), (('boy', 'to'), 0.00851063829787234), (('bed', 'to'), 0.007936507936507936), (('below', 'to'), 0.007575757575757576), (('bad', 'to'), 0.007194244604316547), (('been', 'to'), 0.006882591093117409), (('black', 'to'), 0.00641025641025641), (('be', 'to'), 0.005044136191677175), (('behind', 'to'), 0.004098360655737705), (('being', 'to'), 0.002894356005788712), (('before', 'to'), 0.0010548523206751054), (('by', 'to'), 0.0003919263178522438)]\n",
      "('to', 'the')\n",
      "True\n",
      "[]\n",
      "('the', 'laundry')\n",
      "True\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "sentence = 'He is taken the basket to the laundry'\n",
    "tokens = word_tokenize(sentence.lower())\n",
    "raw = generate_pos_tags(tokens)\n",
    "bgs = list(bigrams(raw[0]))\n",
    "print(bgs)\n",
    "bg_pos = list(bigrams(raw[1]))\n",
    "for bg_entry in bgs:\n",
    "    print(bg_entry)\n",
    "    print(bg_entry in brown_bg)\n",
    "    freqs3 = {}\n",
    "    prob3 = {}\n",
    "    if bg_entry not in brown_bg:\n",
    "        for i, ent in enumerate(bg_entry):\n",
    "            print(ent)\n",
    "            candidates = get_candidates(ent, distance=5)\n",
    "            for candidate in enumerate(candidates):\n",
    "                temp = list(bg_entry)\n",
    "                temp[i] = candidate[1]\n",
    "                e = tuple(temp)\n",
    "                if e in freq_dist_bigrams:\n",
    "                    #print(e)\n",
    "                    #print(freq_dist_bigrams[e])\n",
    "                    freqs3[e] = freq_dist_bigrams[e]\n",
    "                    prob3[e] = freq_dist_bigrams[e]/freq_dist[e[0]]\n",
    "    print(sorted(prob3.items(), key=itemgetter(1), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "6a229562-a838-4519-9b23-c7bebb365181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He', 'is', 'taken', 'the', 'basket', 'to', 'the', 'laundry', '.']\n",
      "[('PRP', 'VBZ', 'VBN'), ('VBZ', 'VBN', 'DT'), ('VBN', 'DT', 'NN'), ('DT', 'NN', 'TO'), ('NN', 'TO', 'DT'), ('TO', 'DT', 'NN'), ('DT', 'NN', '.')]\n"
     ]
    }
   ],
   "source": [
    "sentence = 'He is taken the basket to the laundry.'\n",
    "tokens = word_tokenize(sentence)\n",
    "raw = generate_pos_tags(tokens)\n",
    "tg = raw[0]\n",
    "tg_pos = list(trigrams(raw[1]))\n",
    "print(tg)\n",
    "print(tg_pos)\n",
    "#print(tg_pos)\n",
    "for tg_p in tg_pos:\n",
    "    if tg_p not in freq_dist_tg_pos:\n",
    "        pos_tg_correct = {}\n",
    "        for pos_tg in freq_dist_tg_pos: \n",
    "            if pos_tg[0] == pos_tags[0]:\n",
    "                pos_tg_correct[pos_tg] = freq_dist_tg_pos[pos_tg]/freq_dist_pos[pos_tags[0]]\n",
    "        #sort by the frequency\n",
    "        pos_tg_correct = sorted(pos_tg_correct.items(), key=itemgetter(1), reverse=True)\n",
    "        print(pos_tg_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "2bd7f72f-d2b3-428a-890c-e2340864d5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "907494"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.FreqDist(brown_tg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2512c6b2-fafc-4ea0-b48d-b010cec1f5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('VBZ', 'VBN', 'TO'), 350), (('VBZ', 'JJ', 'TO'), 294), (('VBZ', 'RB', 'TO'), 104), (('VBZ', 'VBG', 'TO'), 76), (('VBZ', 'PRP', 'TO'), 58), (('VBZ', 'NN', 'TO'), 53), (('VBZ', 'IN', 'TO'), 21), (('VBZ', 'NNS', 'TO'), 11), (('VBZ', 'VBD', 'TO'), 11), (('VBZ', 'JJR', 'TO'), 10), (('VBZ', 'CD', 'TO'), 10), (('VBZ', 'NNP', 'TO'), 8), (('VBZ', 'WRB', 'TO'), 7), (('VBZ', 'DT', 'TO'), 5), (('VBZ', 'RBR', 'TO'), 5), (('VBZ', 'JJS', 'TO'), 1), (('VBZ', 'WP', 'TO'), 0), (('VBZ', 'MD', 'TO'), 0), (('VBZ', 'WP$', 'TO'), 0), (('VBZ', 'WDT', 'TO'), 0)]\n"
     ]
    }
   ],
   "source": [
    "t = ('is', 'walk', 'to')\n",
    "tpos = list(trigrams(generate_pos_tags(t)[1]))[0]\n",
    "pp = [brown_tg[i] for i, p in enumerate(brown_tg_pos) if p == tpos]\n",
    "t_fd = {}\n",
    "freqs_4 = {}\n",
    "freqs_5 = {}\n",
    "fd = nltk.FreqDist(pp)\n",
    "for t_ in t:\n",
    "    for p in fd:\n",
    "        if t_ not in t_fd:\n",
    "            t_fd[t_] = 0\n",
    "        if t_ in p:\n",
    "            #print(p)\n",
    "            t_fd[t_] = t_fd[t_] + fd[p]\n",
    "for i, q in enumerate(t_fd):\n",
    "    if t_fd[q] == 0:\n",
    "        candidates = get_candidates(q, distance=5)\n",
    "        for candidate in candidates:\n",
    "            r = list(t)\n",
    "            r[i] = candidate\n",
    "            r = tuple(r)\n",
    "            rpos = list(trigrams(generate_pos_tags(r)[1]))\n",
    "            #print(rpos)\n",
    "            #print(freq_dist_tg_pos[rpos[0]])\n",
    "            freqs_4[rpos[0]] = freq_dist_tg_pos[rpos[0]]\n",
    "            freqs_5[candidate] = freq_dist_trigrams[candidate]\n",
    "print(sorted(freqs_4.items(), key=itemgetter(1), reverse=True))\n",
    "#print(sorted(freqs_4.items(), key=itemgetter(1), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "cc2fe630-e2cf-4949-9faa-671e5f1a0639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('has', 'been', 'the'), ('has', 'been', 'a'), ('has', 'become', 'a'), ('has', 'been', 'an'), ('has', 'been', 'no'), ('has', 'made', 'the'), ('has', 'made', 'a'), ('has', 'raised', 'the'), ('has', 'found', 'a'), ('has', 'seen', 'the'), ('has', 'followed', 'the'), ('is', 'called', 'the'), ('has', 'issued', 'an'), ('has', 'headed', 'the'), ('has', 'used', 'the'), ('has', 'been', 'some'), ('has', 'acquired', 'a'), ('has', 'taken', 'the'), ('has', 'led', 'the'), ('has', 'captured', 'the'), ('has', 'recognized', 'the'), ('has', 'studied', 'the'), ('has', 'had', 'no'), ('has', 'directed', 'a'), ('has', 'become', 'the'), ('has', 'achieved', 'a'), ('has', 'produced', 'a'), ('has', 'designed', 'a'), ('has', 'survived', 'the'), ('has', 'developed', 'the'), ('has', 'changed', 'the'), ('has', 'provided', 'a'), ('has', 'won', 'a'), ('has', 'preoccupied', 'the'), ('has', 'given', 'an'), ('has', 'handed', 'the'), ('is', 'followed', 'a'), ('has', 'caused', 'the'), ('has', 'aroused', 'the'), ('is', 'signed', 'the'), ('has', 'won', 'both'), ('has', 'necessitated', 'this'), ('has', 'taken', 'a'), ('has', 'elected', 'the'), ('has', 'endorsed', 'an'), ('has', 'hit', 'the'), ('has', 'caught', 'the'), ('has', 'asked', 'the'), ('has', 'created', 'a'), ('has', 'updated', 'the'), ('has', 'added', 'some'), ('has', 'undertaken', 'the'), ('has', 'billed', 'the'), ('has', 'brought', 'this'), ('has', 'evoked', 'a'), ('has', 'kept', 'the'), ('has', 'shown', 'a'), ('has', 'made', 'some'), ('has', 'put', 'the'), ('has', 'ordered', 'a'), ('has', 'spent', 'a'), ('has', 'sent', 'a'), ('outbreaks', 'imperiled', 'these'), ('has', 'devised', 'a'), ('has', 'renewed', 'the'), ('has', 'cost', 'the'), ('has', 'reached', 'some'), ('has', 'tagged', 'the'), ('has', 'obtained', 'a'), ('has', 'interposed', 'a'), ('has', 'earned', 'a'), ('has', 'shattered', 'this'), ('has', 'been', 'this'), ('is', 'reported', 'the'), ('has', 'received', 'a'), ('has', 'finished', 'a'), ('has', 'completed', 'the'), ('has', 'arranged', 'a'), ('has', 'urged', 'a'), ('has', 'exploded', 'a'), ('is', 'derived', 'the'), ('has', 'shifted', 'the'), ('has', 'demanded', 'the'), ('has', 'confirmed', 'the'), ('has', 'scribbled', 'a'), ('has', 'gained', 'the'), ('has', 'accomplished', 'some'), ('has', 'chosen', 'a'), ('has', 'stamped', 'the'), ('has', 'turned', 'the'), ('is', 'remembered', 'a'), ('has', 'done', 'a'), ('has', 'catalogued', 'the'), ('has', 'given', 'the'), ('has', 'released', 'a'), ('has', 'developed', 'a'), ('has', 'lost', 'a'), ('has', 'done', 'an'), ('has', 'united', 'the'), ('has', 'measured', 'the'), ('has', 'suffered', 'a'), ('has', 'authorized', 'the'), ('has', 'done', 'this'), ('has', 'met', 'the'), ('has', 'begun', 'a'), ('has', 'acquired', 'some'), ('has', 'achieved', 'the'), ('has', 'judged', 'the'), ('has', 'held', 'the'), ('is', 'given', 'a'), ('has', 'worked', 'a'), ('has', 'introduced', 'a'), ('has', 'given', 'this'), ('has', 'introduced', 'another'), ('has', 'simmered', 'an'), ('has', 'prepared', 'this'), ('is', 'included', 'a'), ('is', 'produced', 'every'), ('has', 'come', 'a'), ('has', 'explored', 'the'), ('has', 'outdistanced', 'the'), ('has', 'published', 'a'), ('has', 'outmoded', 'the'), ('has', 'influenced', 'the'), ('has', 'spurred', 'a'), ('has', 'watched', 'the'), ('has', 'caused', 'a'), ('has', 'sacrificed', 'a'), ('has', 'served', 'a'), ('has', 'cornered', 'the'), ('has', 'collected', 'a'), ('has', 'represented', 'a'), ('has', 'paralleled', 'the'), ('has', 'divided', 'the'), ('is', 'appended', 'a'), ('has', 'illuminated', 'the'), ('has', 'accentuated', 'the'), ('has', 'had', 'a'), ('has', 'forsaken', 'the'), ('has', 'felt', 'the'), ('has', 'selected', 'a'), ('has', 'withstood', 'the'), ('has', 'combined', 'the'), ('has', 'conveyed', 'the'), ('has', 'assumed', 'some'), ('has', 'cited', 'the'), ('has', 'analyzed', 'this'), ('is', 'reached', 'the'), ('has', 'gained', 'some'), ('has', 'entered', 'the'), ('is', 'given', 'some'), ('is', 'nominated', 'the'), ('has', 'seen', 'any'), ('has', 'shown', 'this'), ('commands', 'adopted', 'these'), ('has', 'rent', 'the'), ('has', 'flown', 'a'), ('is', 'called', 'a'), ('cannot', 'become', 'the'), ('has', 'adopted', 'an'), ('has', 'undergone', 'a'), ('has', 'written', 'an'), ('has', 'kept', 'a'), ('has', 'invested', 'the'), ('has', 'proved', 'a'), ('has', 'issued', 'a'), ('is', 'chosen', 'each'), ('has', 'advocated', 'a'), ('is', 'completed', 'a'), ('is', 'wired', 'a'), ('has', 'necessitated', 'a'), ('is', 'held', 'each'), ('is', 'considered', 'an'), ('has', 'added', 'the'), ('has', 'prevented', 'the'), ('has', 'listed', 'the'), ('has', 'calculated', 'the'), ('is', 'derived', 'both'), ('has', 'needed', 'a'), ('has', 'emphasized', 'the'), ('has', 'read', 'a'), ('has', 'left', 'the'), ('has', 'accepted', 'the'), ('has', 'filed', 'an'), ('has', 'rendered', 'an'), ('has', 'approved', 'an'), ('has', 'apportioned', 'this'), ('has', 'yielded', 'a'), ('has', 'surrendered', 'any'), ('has', 'lost', 'all'), ('has', 'evoked', 'this'), ('has', 'sharpened', 'the'), ('is', 'assumed', 'The'), ('has', 'assumed', 'the'), ('is', 'accorded', 'any'), ('has', 'made', 'an'), ('has', 'announced', 'an'), ('is', 'located', 'every'), ('is', 'specified', 'this'), ('is', 'given', 'the'), ('has', 'shot', 'the'), ('has', 'inherited', 'this'), ('has', 'lived', 'all'), ('has', 'perpetrated', 'the'), ('is', 'done', 'that')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'is': 0, 'take': 0, 'to': 0}"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(list(nltk.FreqDist(pp)))\n",
    "for fd in nltk.FreqDist(pp):\n",
    "    for t_ in t:\n",
    "        if t_ not in t_fd:\n",
    "            t_fd[t_] = 0\n",
    "        if t_ in fd:\n",
    "            t_fd[t_] = t_fd[t_]\n",
    "t_fd\n",
    "#for i, tg_pos in enumerate(brown_tg_pos):\n",
    "#    print(brown_tg[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "3fbf0418-43ca-4d24-9ee4-9b051085e046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('IN', 'DT', 'NN'): 25135, ('DT', 'NN', 'IN'): 19413, ('DT', 'JJ', 'NN'): 19175, ('NN', 'IN', 'DT'): 17405, ('IN', 'DT', 'JJ'): 12668, ('JJ', 'NN', 'IN'): 10733, ('NN', 'IN', 'NN'): 7302, ('NNS', 'IN', 'DT'): 5652, ('DT', 'NN', 'NN'): 5594, ('IN', 'DT', 'NNP'): 5483, ...})"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dist_tg_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "1b48efc5-28da-420c-950f-79983d97456f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dist_tg_pos[('VBP', 'VB', 'TO')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "e8070c61-497c-4acc-9e11-2528452b8fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "630"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dist_tg_pos[('VBP', 'TO', 'VB')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58c75d1-1af4-492e-9656-08871ea3cc84",
   "metadata": {},
   "source": [
    "## Real word spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e15a11c0-07d2-42c4-82a3-20a3972e88fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'am', 'running', 'to', 'bus', 'stop', '.'], ['PRP', 'VBP', 'VBG', 'TO', 'VB', 'NN', '.']]\n",
      "Wall time: 0 ns\n",
      "[['I', 'am', 'run', 'to', 'bus', 'stop', '.'], ['PRP', 'VBP', 'VBN', 'TO', 'VB', 'NN', '.']]\n",
      "Wall time: 3.98 ms\n"
     ]
    }
   ],
   "source": [
    "%time print(generate_pos_tags('I am running to bus stop.'))\n",
    "%time print(generate_pos_tags('I am run to bus stop.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261a4c95-2dcc-4130-b133-410dfcd4ca05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1161192"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eea6ce4c-02e8-4201-b210-1f56f065c90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I', 'am')\n",
      "207\n",
      "('am', 'run')\n",
      "0\n",
      "('VBP', 'VBN')\n",
      "2287\n",
      "('run', 'to')\n",
      "6\n",
      "('to', 'bus')\n",
      "0\n",
      "('TO', 'VB')\n",
      "15376\n",
      "('bus', 'store')\n",
      "0\n",
      "('VB', 'NN')\n",
      "1635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor j, tg in enumerate(wtgs):\\n    print(tg)\\n    print(freq_dist_trigrams[tg])\\n    if freq_dist_trigrams[tg] == 0: #if trigrams never occurs\\n        print(ptgs[j])\\n        print(freq_dist_tg_pos[ptgs[j]])\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = generate_pos_tags((word_tokenize('I am run to bus store')))\n",
    "wbgs = list(bigrams(raw[0]))\n",
    "pbgs = list(bigrams(raw[1]))\n",
    "wtgs = list(trigrams(raw[0]))\n",
    "ptgs = list(trigrams(raw[1]))\n",
    "for i, bg in enumerate(wbgs):\n",
    "    print(bg)\n",
    "    print(freq_dist_bigrams[bg])\n",
    "    if freq_dist_bigrams[bg] == 0: #if bigrams never occurs        \n",
    "        print(pbgs[i])\n",
    "        print(freq_dist_bg_pos[pbgs[i]])\n",
    "'''\n",
    "for j, tg in enumerate(wtgs):\n",
    "    print(tg)\n",
    "    print(freq_dist_trigrams[tg])\n",
    "    if freq_dist_trigrams[tg] == 0: #if trigrams never occurs\n",
    "        print(ptgs[j])\n",
    "        print(freq_dist_tg_pos[ptgs[j]])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e7175089-5ac5-4de7-9cd0-b4819a9dcd7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'VBP' in freq_dist_bg_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38947c65-1312-4442-a720-a498a5407098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dist_tg_pos[('PRP', 'VBP', 'VBG')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc071473",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS=brown.words(categories='news')\n",
    "def known(words): return set(w for w in words if w in WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac02de2-eb2c-41d3-8809-f289d7a6ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for edit in list(edits1('run')):\n",
    "    print(edit[0])\n",
    "    print(edit in ind[edit[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f517fae8-2b2f-4546-8281-b01a0d65b4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3b5847-e0dc-422a-80c3-4e5957c76c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a09674-468f-457a-940f-e5867ce38188",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_words = words.words()\n",
    "\n",
    "word = 'rin'\n",
    "incorrect_words = 'The quick brwon fxo jumps over rin the callobrtion dog'\n",
    "\n",
    "\n",
    "#for word in incorrect_words:\n",
    "    #temp = [(edit_distance(word, w),w) for w in correct_words if w[0]==word[0]]\n",
    "    #print(temp)\n",
    "#edits1_set_jac = sorted(temp, key = lambda val:val[0])[0]\n",
    "for incorrect_word in word_tokenize(incorrect_words):\n",
    "    if incorrect_word not in words.words():\n",
    "        print(\"Wrong word: \" + incorrect_word)\n",
    "        freqs_1 = {}\n",
    "        freqs_2 = {}\n",
    "        %time edits1_set = set([edit for edit in list(edits1(incorrect_word)) if edit in ind[edit[0].lower()]])\n",
    "        %time edits2_set = set([edit for edit in list(edits2(incorrect_word)) if edit in ind[edit[0].lower()]])\n",
    "        for word_ in edits1_set:\n",
    "            freqs_1[word_] = freq_dist[word_]\n",
    "        for word_ in edits2_set:\n",
    "            freqs_2[word_] = freq_dist[word_]\n",
    "        print(freqs_1)\n",
    "        print(freqs_2)\n",
    "        #print(sorted(freqs_1, key = lambda val:val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58ec49b-8cb9-4169-b508-16d88bf0f9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = \"I rin everyday in the evening.\"\n",
    "raw_pos_tags = generate_pos_tags(words)\n",
    "bigrams_words = list(bigrams(raw_pos_tags[0]))\n",
    "trigrams_words = list(trigrams(raw_pos_tags[0]))\n",
    "bigrams_pos = list(bigrams(raw_pos_tags[1]))\n",
    "trigrams_pos = list(trigrams(raw_pos_tags[1]))\n",
    "print(bigrams_words)\n",
    "print(trigrams_words)\n",
    "print(bigrams_pos)\n",
    "print(trigrams_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8f2e25b5-a5f4-4326-8e58-9d811da5ab3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I', 'am', 'rain', 'to', 'the', 'bus', 'stop'],\n",
       " ['PRP', 'VBP', 'RB', 'TO', 'DT', 'NN', 'NN']]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_pos_tags(\"I am rain to the bus stop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f72e7174-1931-4986-b92e-7d4535535d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I', 'am', 'raining', 'to', 'the', 'bus', 'stop'],\n",
       " ['PRP', 'VBP', 'VBG', 'TO', 'DT', 'NN', 'NN']]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_pos_tags(\"I am raining to the bus stop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "97e55e51-18d9-4f76-a8d3-98ae5abb9226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist(trigrams(words_tags_list[1]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62af3abf-9196-490f-a8fe-3c8aec0bd0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
